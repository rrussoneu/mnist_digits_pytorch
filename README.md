# mnist_digits_pytorch

This project uses a simple deep network for digit classification. The network is trained and tested using the MNIST data set, providing an example of how deep networks can be used to solve classification problems. After training, the filters created by the model are analyzed. The network is further used to classify Greek letters after being trained on the MNSIT data set. A small sample of letters are used for the transfer learning stage of this project. A variety of networks are tested at the end of the project, using different layers, activation functions, drop-out percentages, batch sizes, and epochs. These models all performed well, and the final accuracy is saved in an included csv file. Finally, the original network from part one of this project has its first layer changed. This experimental model uses a set of 10 5x5 Gabor filters as the first layer, and it is run through the same process as part one, while also being tested in a similar fashion on Greek letters. Aside from the provided data, a small set of digits and Greek letters I drew are used to test the results as well.